{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('thesis.env')\n",
    "\n",
    "from get_completion import get_completion_ollama, get_completion_claude3, get_completion_gpt, get_completion_llama_replicate\n",
    "from metrics import cleanup_result_first, cleanup_result_last, metrics_mine, metrics_mine_dict, plot_confusion_matrix\n",
    "from costs import get_completion_gpt_with_cost, get_completion_claude3_with_cost, get_completion_llama_replicate_with_cost\n",
    "from helper_functions import load_text_files, get_embedding, choose_in_context_examples, choose_in_context_examples_2,\\\n",
    "prepare_fewshot_system_content, prepare_fewshot_prompt, append_context, append_context_and_source, appending_contract_to_prompt,\\\n",
    "sample_in_context_examples\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import anthropic\n",
    "import voyageai\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import ast\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ic_examples = pd.read_csv('ic_examples_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_whole = pd.read_csv('whole_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_clauses = df_test['clause'].tolist()\n",
    "test_risks = df_test['ground_truth_label'].tolist()\n",
    "test_contract_types = df_test['contract_type'].tolist()\n",
    "test_representing = df_test['representing'].tolist()\n",
    "test_sources = df_test['source'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = len(test_clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_content_step_by_step = f'You are a lawyer. Can you assess the risk of the following contract clause? \\n The options are: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'\n",
    "# in this system message, I don't include stuff like answer with this only as we want to produce cot first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def result_dataframe(experiment_name, init_system_content, model, setting, cleanining_method = 'basic', save_dir = 'results', init_prompt = None, which_ic_embed_type = None, n_fewshot_embed = None):\n",
    "    \"\"\"\n",
    "    runs the test and returns a dataframe with all the necessary info\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = [] # list of dictionaries for each test data point\n",
    "    list_for_metrics = [] # this is the cleaned results for calculating performance at the end\n",
    "    N = 200 \n",
    "\n",
    "    if model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo', 'gpt-3.5-turbo-instruct']:\n",
    "        for i in tqdm(range(N)):\n",
    "\n",
    "            if setting == 'normal':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i], test_representing[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'few_shot_system': # in context examples in the system message\n",
    "                system_content = init_system_content # prepare it in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_prompt': # in context examples in the prompt\n",
    "                system_content = init_system_content \n",
    "                prompt = f\"{init_prompt}\\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer: \"\n",
    "                #init_prompt += f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\"\n",
    "                #prompt = init_prompt\n",
    "            elif setting == 'step_by_step':\n",
    "                cot_step_reasoning = get_completion_gpt(prompt= f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step.', system_content= init_system_content, model=model) # init system content is the step by step system content\n",
    "                system_content = init_system_content\n",
    "                prompt = f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step. {cot_step_reasoning} \\nTherefore, the answer (only one of potential issue or red flag) is'\n",
    "            elif setting == 'annollm': # examples in the prompt\n",
    "                system_content = init_system_content\n",
    "                prompt = f\"{init_prompt} \\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" # init prompt is prepared in advance\n",
    "            \n",
    "            \n",
    "            elif setting == 'annollm_system': \n",
    "                system_content = init_system_content # prepare in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" \n",
    "            \n",
    "            \n",
    "            elif setting == 'append_contract': # in system message\n",
    "                system_content = append_context_and_source(init_system_content,test_contract_types[i],test_representing[i],test_sources[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'append_contract_in_prompt':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i],test_representing[i])\n",
    "                prompt = appending_contract_to_prompt(test_clauses[i],test_sources[i])\n",
    "            elif setting == 'few_shot_embed_system': # in context examples are in the system message\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = prepare_fewshot_system_content(init_system_content,relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_embed_prompt': # ic examples are in the prompt\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = init_system_content\n",
    "                init_prompt = prepare_fewshot_prompt(relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                init_prompt += f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\"\n",
    "                prompt = init_prompt\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Unsupported setting')\n",
    "\n",
    "            model_output, input_tokens, output_tokens, total_cost = get_completion_gpt_with_cost(prompt, system_content, model)\n",
    "\n",
    "            if cleanining_method == 'basic':\n",
    "                cleaned_prediction = model_output\n",
    "            elif cleanining_method == 'extract_last':\n",
    "                cleaned_prediction = cleanup_result_last(model_output)\n",
    "            elif cleanining_method == 'extract_first':\n",
    "                cleaned_prediction = cleanup_result_first(model_output)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported cleaning method\")\n",
    "            \n",
    "            list_for_metrics.append(cleaned_prediction)\n",
    "\n",
    "            result = {\n",
    "                'experiment_name': experiment_name,\n",
    "                'model': model,\n",
    "                'system_content': system_content,\n",
    "                'prompt': prompt,\n",
    "                'clause': test_clauses[i],\n",
    "                'contract_type': test_contract_types[i],\n",
    "                'representing': test_representing[i],\n",
    "                'source': test_sources[i],\n",
    "                'ground_truth_label': test_risks[i],\n",
    "                'model_output': model_output,\n",
    "                'cleaned_prediction': cleaned_prediction,\n",
    "                'number of input tokens': input_tokens,\n",
    "                'number of output tokens': output_tokens,\n",
    "                'cost': total_cost\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        metrics = metrics_mine_dict(test_risks[:N], list_for_metrics)\n",
    "        results_df['accuracy'] = metrics['Accuracy']\n",
    "        results_df['precision'] = metrics['Precision']\n",
    "        results_df['recall'] = metrics['Recall']\n",
    "        results_df['F1'] = metrics['F1']\n",
    "\n",
    "        results_df['total cost of this experiment'] = results_df['cost'].sum()\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        results_df['experiment ran for (seconds)'] = elapsed_time\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pickle_path = os.path.join(save_dir, f'{experiment_name} {model}.pkl')\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(results_df, f)\n",
    "\n",
    "        return results_df\n",
    "    \n",
    "    \n",
    "    elif model in ['claude-3-opus-20240229', 'claude-3-sonnet-20240229', 'claude-3-haiku-20240307', 'claude-3-5-sonnet-20240620']:\n",
    "        for i in tqdm(range(N)):\n",
    "\n",
    "            if setting == 'normal':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i], test_representing[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'few_shot_system':\n",
    "                system_content = init_system_content # prepare it in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_prompt': # in context examples in the prompt\n",
    "                system_content = init_system_content\n",
    "                prompt = f\"{init_prompt}\\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer: \"     \n",
    "            elif setting == 'step_by_step':\n",
    "                cot_step_reasoning = get_completion_claude3(prompt= f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step.', system_content= init_system_content, model=model) # init system content is the step by step system content\n",
    "                system_content = init_system_content\n",
    "                prompt = f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step. {cot_step_reasoning} \\nTherefore, the answer (only one of potential issue or red flag) is'\n",
    "            elif setting == 'annollm':\n",
    "                system_content = init_system_content\n",
    "                prompt = f\"{init_prompt} \\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" # init prompt is prepared in advance\n",
    "                \n",
    "            elif setting == 'annollm_system':\n",
    "                system_content = init_system_content # prepare in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" \n",
    "            \n",
    "            elif setting == 'append_contract':\n",
    "                system_content = append_context_and_source(init_system_content,test_contract_types[i],test_representing[i],test_sources[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'append_contract_in_prompt':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i],test_representing[i])\n",
    "                prompt = appending_contract_to_prompt(test_clauses[i],test_sources[i])\n",
    "            elif setting == 'few_shot_embed_system': # in context examples are in the system message\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = prepare_fewshot_system_content(init_system_content,relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_embed_prompt': # ic examples are in the prompt\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = init_system_content\n",
    "                init_prompt = prepare_fewshot_prompt(relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                init_prompt += f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\"\n",
    "                prompt = init_prompt\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Unsupported setting')\n",
    "\n",
    "            model_output, input_tokens, output_tokens, total_cost = get_completion_claude3_with_cost(prompt, system_content, model)\n",
    "\n",
    "            if cleanining_method == 'basic':\n",
    "                cleaned_prediction = model_output\n",
    "            elif cleanining_method == 'extract_last':\n",
    "                cleaned_prediction = cleanup_result_last(model_output)\n",
    "            elif cleanining_method == 'extract_first':\n",
    "                cleaned_prediction = cleanup_result_first(model_output)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported cleaning method\")\n",
    "            \n",
    "            list_for_metrics.append(cleaned_prediction)\n",
    "\n",
    "            result = {\n",
    "                'experiment_name': experiment_name,\n",
    "                'model': model,\n",
    "                'system_content': system_content,\n",
    "                'prompt': prompt,\n",
    "                'clause': test_clauses[i],\n",
    "                'contract_type': test_contract_types[i],\n",
    "                'representing': test_representing[i],\n",
    "                'source': test_sources[i],\n",
    "                'ground_truth_label': test_risks[i],\n",
    "                'model_output': model_output,\n",
    "                'cleaned_prediction': cleaned_prediction,\n",
    "                'number of input tokens': input_tokens,\n",
    "                'number of output tokens': output_tokens,\n",
    "                'cost': total_cost\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        metrics = metrics_mine_dict(test_risks[:N], list_for_metrics)\n",
    "        results_df['accuracy'] = metrics['Accuracy']\n",
    "        results_df['precision'] = metrics['Precision']\n",
    "        results_df['recall'] = metrics['Recall']\n",
    "        results_df['F1'] = metrics['F1']\n",
    "\n",
    "        results_df['total cost of this experiment'] = results_df['cost'].sum()\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        results_df['experiment ran for (seconds)'] = elapsed_time\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pickle_path = os.path.join(save_dir, f'{experiment_name} {model}.pkl')\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(results_df, f)\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    \n",
    "\n",
    "    elif model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "        for i in tqdm(range(N)):\n",
    "\n",
    "            if setting == 'normal':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i], test_representing[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'few_shot_system': # in context examples in the system message\n",
    "                system_content = init_system_content # prepare it in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_prompt': # in context examples in the prompt\n",
    "                system_content = init_system_content \n",
    "                prompt = f\"{init_prompt}\\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer: \"\n",
    "            elif setting == 'step_by_step':\n",
    "                cot_step_reasoning = get_completion_llama_replicate(prompt= f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step.', system_message= init_system_content, model=model) # init system content is the step by step system content\n",
    "                system_content = init_system_content\n",
    "                prompt = f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step. {cot_step_reasoning} \\nTherefore, the answer (only one of potential issue or red flag) is'\n",
    "            elif setting == 'annollm': # examples in the prompt\n",
    "                system_content = init_system_content\n",
    "                prompt = f\"{init_prompt} \\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" # init prompt is prepared in advance\n",
    "            \n",
    "            \n",
    "            elif setting == 'annollm_system': # try this with low N before running the whole thing - copy to others if it is working\n",
    "                system_content = init_system_content # prepare in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" \n",
    "            \n",
    "            \n",
    "            elif setting == 'append_contract': # in system message\n",
    "                system_content = append_context_and_source(init_system_content,test_contract_types[i],test_representing[i],test_sources[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'append_contract_in_prompt':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i],test_representing[i])\n",
    "                prompt = appending_contract_to_prompt(test_clauses[i],test_sources[i])\n",
    "            elif setting == 'few_shot_embed_system': # in context examples are in the system message\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = prepare_fewshot_system_content(init_system_content,relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_embed_prompt': # ic examples are in the prompt\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = init_system_content\n",
    "                init_prompt = prepare_fewshot_prompt(relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                init_prompt += f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\"\n",
    "                prompt = init_prompt\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Unsupported setting')\n",
    "\n",
    "            model_output, input_tokens, output_tokens, total_cost = get_completion_llama_replicate_with_cost(prompt, system_content, model)\n",
    "\n",
    "            if cleanining_method == 'basic':\n",
    "                cleaned_prediction = model_output\n",
    "            elif cleanining_method == 'extract_last':\n",
    "                cleaned_prediction = cleanup_result_last(model_output)\n",
    "            elif cleanining_method == 'extract_first':\n",
    "                cleaned_prediction = cleanup_result_first(model_output)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported cleaning method\")\n",
    "            \n",
    "            list_for_metrics.append(cleaned_prediction)\n",
    "\n",
    "            result = {\n",
    "                'experiment_name': experiment_name,\n",
    "                'model': model,\n",
    "                'system_content': system_content,\n",
    "                'prompt': prompt,\n",
    "                'clause': test_clauses[i],\n",
    "                'contract_type': test_contract_types[i],\n",
    "                'representing': test_representing[i],\n",
    "                'source': test_sources[i],\n",
    "                'ground_truth_label': test_risks[i],\n",
    "                'model_output': model_output,\n",
    "                'cleaned_prediction': cleaned_prediction,\n",
    "                'number of input tokens': input_tokens,\n",
    "                'number of output tokens': output_tokens,\n",
    "                'cost': total_cost\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        metrics = metrics_mine_dict(test_risks[:N], list_for_metrics)\n",
    "        results_df['accuracy'] = metrics['Accuracy']\n",
    "        results_df['precision'] = metrics['Precision']\n",
    "        results_df['recall'] = metrics['Recall']\n",
    "        results_df['F1'] = metrics['F1']\n",
    "\n",
    "        results_df['total cost of this experiment'] = results_df['cost'].sum()\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        results_df['experiment ran for (seconds)'] = elapsed_time\n",
    "        \n",
    "        \n",
    "        if model == 'meta/meta-llama-3-8b-instruct':\n",
    "            model_name = 'meta:llama3:8b'\n",
    "        elif model == 'meta/meta-llama-3-70b-instruct':\n",
    "            model_name = 'meta:llama3:70b'\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pickle_path = os.path.join(save_dir, f'{experiment_name} {model_name}.pkl')\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(results_df, f)\n",
    "\n",
    "        return results_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif model in ['unsloth_model:latest', 'unsloth_model_3_epochs:latest', 'llama3:8b']: # no cost for these\n",
    "        for i in tqdm(range(N)):\n",
    "\n",
    "            if setting == 'normal':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i], test_representing[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'few_shot_system': # in context examples in the system message\n",
    "                system_content = init_system_content # prepare it in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_prompt': # in context examples in the prompt\n",
    "                system_content = init_system_content \n",
    "                prompt = f\"{init_prompt}\\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer: \"\n",
    "            elif setting == 'step_by_step':\n",
    "                cot_step_reasoning = get_completion_llama_replicate(prompt= f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step.', system_message= init_system_content, model=model) # init system content is the step by step system content\n",
    "                system_content = init_system_content\n",
    "                prompt = f'Clause: {test_clauses[i]}  \\nAnswer: Let\\'s think step by step. {cot_step_reasoning} \\nTherefore, the answer (only one of potential issue or red flag) is'\n",
    "            elif setting == 'annollm': # examples in the prompt\n",
    "                system_content = init_system_content\n",
    "                prompt = f\"{init_prompt} \\nInformation: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" # init prompt is prepared in advance\n",
    "            \n",
    "            \n",
    "            elif setting == 'annollm_system': # try this with low N before running the whole thing - copy to others if it is working\n",
    "                system_content = init_system_content # prepare in advance\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\" \n",
    "            \n",
    "            \n",
    "            elif setting == 'append_contract': # in system message\n",
    "                system_content = append_context_and_source(init_system_content,test_contract_types[i],test_representing[i],test_sources[i])\n",
    "                prompt = test_clauses[i]\n",
    "            elif setting == 'append_contract_in_prompt':\n",
    "                system_content = append_context(init_system_content,test_clauses[i],test_contract_types[i],test_representing[i])\n",
    "                prompt = appending_contract_to_prompt(test_clauses[i],test_sources[i])\n",
    "            elif setting == 'few_shot_embed_system': # in context examples are in the system message\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = prepare_fewshot_system_content(init_system_content,relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                prompt = f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\n Clause: {test_clauses[i]} \\n Answer:\"\n",
    "            elif setting == 'few_shot_embed_prompt': # ic examples are in the prompt\n",
    "                if which_ic_embed_type == 'not_per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                elif which_ic_embed_type == 'per_class':\n",
    "                    relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type = choose_in_context_examples_2(test_clauses[i],df_ic_examples,n_fewshot_embed)\n",
    "                else:\n",
    "                    raise ValueError('Choose a valid way of picking embedding ic examples: \"per_class\" or \"not_per_class\"')\n",
    "                system_content = init_system_content\n",
    "                init_prompt = prepare_fewshot_prompt(relevant_clauses, relevant_risks, relevant_representing, relevant_contract_type)\n",
    "                init_prompt += f\"Information: The type of this contract is {test_contract_types[i]}. Representing side is the {test_representing[i]}. The governing law is England and Wales. \\nClause: {test_clauses[i]} \\nAnswer:\"\n",
    "                prompt = init_prompt\n",
    "\n",
    "            \n",
    "            else:\n",
    "                raise ValueError('Unsupported setting')\n",
    "\n",
    "            model_output = get_completion_ollama(prompt, system_content, model)\n",
    "\n",
    "            if cleanining_method == 'basic':\n",
    "                cleaned_prediction = model_output\n",
    "            elif cleanining_method == 'extract_last':\n",
    "                cleaned_prediction = cleanup_result_last(model_output)\n",
    "            elif cleanining_method == 'extract_first':\n",
    "                cleaned_prediction = cleanup_result_first(model_output)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported cleaning method\")\n",
    "            \n",
    "            list_for_metrics.append(cleaned_prediction)\n",
    "\n",
    "            result = {\n",
    "                'experiment_name': experiment_name,\n",
    "                'model': model,\n",
    "                'system_content': system_content,\n",
    "                'prompt': prompt,\n",
    "                'clause': test_clauses[i],\n",
    "                'contract_type': test_contract_types[i],\n",
    "                'representing': test_representing[i],\n",
    "                'source': test_sources[i],\n",
    "                'ground_truth_label': test_risks[i],\n",
    "                'model_output': model_output,\n",
    "                'cleaned_prediction': cleaned_prediction,\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        metrics = metrics_mine_dict(test_risks[:N], list_for_metrics)\n",
    "        results_df['accuracy'] = metrics['Accuracy']\n",
    "        results_df['precision'] = metrics['Precision']\n",
    "        results_df['recall'] = metrics['Recall']\n",
    "        results_df['F1'] = metrics['F1']\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        results_df['experiment ran for (seconds)'] = elapsed_time\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        pickle_path = os.path.join(save_dir, f'{experiment_name} {model}.pkl')\n",
    "        with open(pickle_path, 'wb') as f:\n",
    "            pickle.dump(results_df, f)\n",
    "\n",
    "        return results_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = 'Basic zero-shot prompting.'\n",
    "init_system_content_zeroshot_noinfo = 'You are a lawyer. Assess the risk of the following contract clause. Answer with one of these two options and nothing else: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('Basic zero-shot prompting',init_system_content_zeroshot_noinfo, model, 'normal','basic','results')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('Basic zero-shot prompting',init_system_content_zeroshot_noinfo, model, 'normal','basic','results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'meta/meta-llama-3-8b-instruct'\n",
    "result_dataframe('Basic zero-shot prompting',init_system_content_zeroshot_noinfo, model, 'normal','basic','results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'meta/meta-llama-3-70b-instruct'\n",
    "result_dataframe('Basic zero-shot prompting',init_system_content_zeroshot_noinfo, model, 'normal','basic','results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('Basic zero-shot prompting',init_system_content_zeroshot_noinfo, model, 'normal','basic','results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot CoT with legal reasoning template B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_system_content_legal_template = 'You are a lawyer. Assess the risk of the following contract clause. \\\n",
    "There are two risk types: potential issue and red flag. \\\n",
    "Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk. \\\n",
    "Use this legal reasoning approach: topic, rule, explanation, analysis, counterarguments, conclusion. \\\n",
    "Don\\'t use more than 6 sentences and only give the risk type as conclusion.\\\n",
    "'\n",
    "# for this one when cleaning the results, we need the use the cleaning function that takes the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('zero-shot cot with legal template',init_system_content_legal_template, model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('zero-shot cot with legal template',init_system_content_legal_template, model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('zero-shot cot with legal template',init_system_content_legal_template, model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('zero-shot cot with legal template',init_system_content_legal_template, model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot Prompting\n",
    "examples in the system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ic_clause_pi_1 = df_ic_examples['clause'][1417]\n",
    "ic_representing_pi_1 = df_ic_examples['representing'][1417]\n",
    "ic_contract_type_pi_1 = df_ic_examples['contract_type'][1417]\n",
    "ic_risk_pi = df_ic_examples['ground_truth_label'][1417]\n",
    "\n",
    "ic_clause_pi_2 = df_ic_examples['clause'][2874]\n",
    "ic_representing_pi_2 = df_ic_examples['representing'][2874]\n",
    "ic_contract_type_pi_2 = df_ic_examples['contract_type'][2874]\n",
    "\n",
    "ic_clause_pi_3 = df_ic_examples['clause'][2586]\n",
    "ic_representing_pi_3 =  df_ic_examples['representing'][2586]\n",
    "ic_contract_type_pi_3 = df_ic_examples['contract_type'][2586]\n",
    "\n",
    "\n",
    "ic_clause_rf_1 = df_ic_examples['clause'][3595]\n",
    "ic_representing_rf_1 = df_ic_examples['representing'][3595]\n",
    "ic_contract_type_rf_1 = df_ic_examples['contract_type'][3595]\n",
    "ic_risk_rf = df_ic_examples['ground_truth_label'][3595]\n",
    "\n",
    "ic_clause_rf_2 = df_ic_examples['clause'][333]\n",
    "ic_representing_rf_2 = df_ic_examples['representing'][333]\n",
    "ic_contract_type_rf_2 = df_ic_examples['contract_type'][333]\n",
    "\n",
    "\n",
    "ic_clause_rf_3 = df_ic_examples['clause'][121]\n",
    "ic_representing_rf_3 = df_ic_examples['representing'][121]\n",
    "ic_contract_type_rf_3 = df_ic_examples['contract_type'][121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ic_clauses_1 = [ic_clause_pi_1, ic_clause_rf_1]\n",
    "ic_risks_1 = [ic_risk_pi, ic_risk_rf]\n",
    "ic_representing_1 = [ic_representing_pi_1, ic_representing_rf_1]\n",
    "ic_contract_type_1 = [ic_contract_type_pi_1, ic_contract_type_rf_1]\n",
    "\n",
    "\n",
    "ic_clauses_2 = [ic_clause_pi_1, ic_clause_pi_2, ic_clause_rf_1, ic_clause_rf_2]\n",
    "ic_risks_2 = [ic_risk_pi, ic_risk_pi, ic_risk_rf, ic_risk_rf]\n",
    "ic_representing_2 = [ic_representing_pi_1,ic_representing_pi_2, ic_representing_rf_1, ic_representing_rf_2]\n",
    "ic_contract_type_2 = [ic_contract_type_pi_1,ic_contract_type_pi_2, ic_contract_type_rf_1,ic_contract_type_rf_2]\n",
    "\n",
    "ic_clauses_3 = [ic_clause_pi_1, ic_clause_pi_2, ic_clause_pi_3, ic_clause_rf_1, ic_clause_rf_2, ic_clause_rf_3]\n",
    "ic_risks_3 = [ic_risk_pi, ic_risk_pi, ic_risk_pi, ic_risk_rf, ic_risk_rf, ic_risk_rf]\n",
    "ic_representing_3 = [ic_representing_pi_1,ic_representing_pi_2, ic_representing_pi_3, ic_representing_rf_1, ic_representing_rf_2, ic_representing_rf_3]\n",
    "ic_contract_type_3 = [ic_contract_type_pi_1,ic_contract_type_pi_2, ic_contract_type_pi_3, ic_contract_type_rf_1,ic_contract_type_rf_2, ic_contract_type_rf_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Putting the in-context examples in the system message ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_system_content_fewshot = f'You are a lawyer. Assess the risk of the following contract clause. \\nAnswer with one of these two options and nothing else: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'\n",
    "\n",
    "system_content_fewshot_1 = prepare_fewshot_system_content(init_system_content_fewshot, ic_clauses_1, ic_risks_1, ic_representing_1, ic_contract_type_1) # 3 in-context examples\n",
    "system_content_fewshot_2 = prepare_fewshot_system_content(init_system_content_fewshot, ic_clauses_2, ic_risks_2, ic_representing_2, ic_contract_type_2) # 6 in-context examples\n",
    "system_content_fewshot_3 = prepare_fewshot_system_content(init_system_content_fewshot, ic_clauses_3, ic_risks_3, ic_representing_3, ic_contract_type_3) # 9 in-context examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('few-shot with 1 example per class',system_content_fewshot_1, model, 'few_shot_system','extract_last')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few-shot with 1 example per class',system_content_fewshot_1, model, 'few_shot_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('few-shot with 2 examples per class',system_content_fewshot_2, model, 'few_shot_system','extract_last')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few-shot with 2 examples per class',system_content_fewshot_2, model, 'few_shot_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('few-shot with 3 examples per class',system_content_fewshot_3, model, 'few_shot_system','extract_last')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few-shot with 3 examples per class',system_content_fewshot_3, model, 'few_shot_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few-shot with 1 example per class',system_content_fewshot_1, model, 'few_shot_system','extract_last')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few-shot with 2 examples per class',system_content_fewshot_2, model, 'few_shot_system','extract_last')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few-shot with 3 examples per class',system_content_fewshot_3, model, 'few_shot_system','extract_last') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('few-shot with 1 example per class',system_content_fewshot_1, model, 'few_shot_system','extract_last') \n",
    "    result_dataframe('few-shot with 2 examples per class',system_content_fewshot_2, model, 'few_shot_system','extract_last')    \n",
    "    result_dataframe('few-shot with 3 examples per class',system_content_fewshot_3, model, 'few_shot_system','extract_last') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting\n",
    "examples in the user message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_system_content_fewshot = f'You are a lawyer. Assess the risk of the following contract clause. \\nAnswer with one of these two options and nothing else: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_fewshot_1 = prepare_fewshot_prompt(ic_clauses_1, ic_risks_1, ic_representing_1, ic_contract_type_1)\n",
    "prompt_fewshot_2 = prepare_fewshot_prompt(ic_clauses_2, ic_risks_2, ic_representing_2, ic_contract_type_2)\n",
    "prompt_fewshot_3 = prepare_fewshot_prompt(ic_clauses_3, ic_risks_3, ic_representing_3, ic_contract_type_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few-shot with 1 example per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few-shot with 2 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo', 'gpt-4']:\n",
    "    result_dataframe('few-shot with 3 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few-shot with 1 example per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few-shot with 2 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few-shot with 3 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few-shot with 1 example per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few-shot with 2 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few-shot with 3 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('few-shot with 1 example per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_1) \n",
    "    result_dataframe('few-shot with 2 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_2)\n",
    "    result_dataframe('few-shot with 3 examples per class, examples in prompt',init_system_content_fewshot,model,setting = 'few_shot_prompt',init_prompt=prompt_fewshot_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot CoT with legal reasoning template A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_system_content_alex_template = \"\"\"\\\n",
    "You are a lawyer. Your task is to asses the risk of the given contract clause.\n",
    "Follow this format:\n",
    "Clause: {}. \n",
    "Thought: Your thought process for assessing the clause. \n",
    "Result: 'potential issue' if the clause has potential legal risk or 'red flag' if there is high legal risk. \n",
    "Justification: An explanation for the result you've reached.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('zero-shot cot with alex template',init_system_content_alex_template,model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('zero-shot cot with alex template',init_system_content_alex_template,model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('zero-shot cot with alex template',init_system_content_alex_template,model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('zero-shot cot with alex template',init_system_content_alex_template,model, 'normal','extract_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot CoT, let's think step by step \n",
    "\n",
    "in this one we prompt the models twice: first, to generate the cot produced by let's think step by step \n",
    "and then we append this to the input and 'Therefore, the answer (potential issue or red flag) is'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_content_step_by_step = f'You are a lawyer. Assess the risk of the following contract clause. \\n The options are: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'\n",
    "# in this system message, I don't include stuff like answer with this only as we want to produce cot first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('lets think step by step',system_content_step_by_step,model,'step_by_step','extract_first')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('lets think step by step',system_content_step_by_step,model,'step_by_step','extract_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('lets think step by step',system_content_step_by_step,model,'step_by_step','extract_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('lets think step by step',system_content_step_by_step,model,'step_by_step','extract_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AnnoLLM\n",
    "explanations generated with gpt4o \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_content_annollm = 'You are a lawyer. Your expertise is to classify the legal risk of contractual clauses. There are two possible classifications: \"potential issue\" or \"red flag\". Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_llm_explanations(ic_clauses, ic_risks, ic_representing, ic_contract_type, system_content = system_content_annollm, model = 'gpt-4o'):\n",
    "    explanations = []\n",
    "    for i in range(len(ic_risks)):\n",
    "        prompt = f'Information: The type of this contract is {ic_contract_type[i]}. Representing side is the {ic_representing[i]}. The governing law is England and Wales. Given the clause: \" {ic_clauses[i]} \", explain briefly why the correct classification is \" {ic_risks[i]} \", with a response length not exceeding 100 words.'\n",
    "        explanations.append(get_completion_gpt(prompt=prompt, system_content=system_content, model= model))\n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examples in the user message\n",
    "\n",
    "def prepare_fewshot_cot_prompt_annollm(ic_clauses, ic_risks, ic_representing, ic_contract_type, test_clause = None):\n",
    "    explanations = generate_llm_explanations(ic_clauses, ic_risks, ic_representing, ic_contract_type)\n",
    "    prompt = \"\"\n",
    "    for clause,risk,explanation, representing, contract_type in zip(ic_clauses,ic_risks,explanations, ic_representing, ic_contract_type):\n",
    "        prompt += f\"Information: The type of this contract is {contract_type}. Representing side is the {representing}. The governing law is England and Wales. \\nClause: {clause} \\nAnswer: {explanation} Therefore, the classification is {risk}. \\n\\n\"\n",
    "    #prompt += f\"Clause: {test_clause} \\nAnswer:\" # append this later for efficiency in the next cell\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_prompt_annollm_1 = prepare_fewshot_cot_prompt_annollm(ic_clauses_1,ic_risks_1, ic_representing_1, ic_contract_type_1)\n",
    "init_prompt_annollm_2 = prepare_fewshot_cot_prompt_annollm(ic_clauses_2,ic_risks_2, ic_representing_2, ic_contract_type_2)\n",
    "init_prompt_annollm_3 = prepare_fewshot_cot_prompt_annollm(ic_clauses_3,ic_risks_3, ic_representing_3, ic_contract_type_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo-0125'\n",
    "result_dataframe('annollm with 1 example per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_1)\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_2)\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside prompt',system_content_annollm,model,'annollm','extract_last',init_prompt=init_prompt_annollm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annollm but with examples inside the system message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_fewshot_cot_system_content_annollm(init_system_message,ic_clauses, ic_risks, ic_representing, ic_contract_type):\n",
    "    init_system_message += '\\nHere are some examples to help you: \\n '\n",
    "    explanations = generate_llm_explanations(ic_clauses, ic_risks, ic_representing, ic_contract_type)\n",
    "    for clause,risk,explanation, representing, contract_type in zip(ic_clauses,ic_risks,explanations, ic_representing, ic_contract_type):\n",
    "        init_system_message +=  f\"Information: The type of this contract is {contract_type}. Representing side is the {representing}. The governing law is England and Wales. \\nClause: {clause} \\nAnswer: {explanation} Therefore, the classification is {risk}. \\n\\n\"\n",
    "    return init_system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_content_annollm_1 = prepare_fewshot_cot_system_content_annollm(system_content_annollm, ic_clauses_1, ic_risks_1, ic_representing_1, ic_contract_type_1)\n",
    "system_content_annollm_2 = prepare_fewshot_cot_system_content_annollm(system_content_annollm, ic_clauses_2, ic_risks_2, ic_representing_2, ic_contract_type_2)\n",
    "system_content_annollm_3 = prepare_fewshot_cot_system_content_annollm(system_content_annollm, ic_clauses_3, ic_risks_3, ic_representing_3, ic_contract_type_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside system message',system_content_annollm_1,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside system message',system_content_annollm_2,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4','gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside system message',system_content_annollm_3,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside system message',system_content_annollm_1,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside system message',system_content_annollm_2,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside system message',system_content_annollm_3,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside system message',system_content_annollm_1,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside system message',system_content_annollm_2,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside system message',system_content_annollm_3,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('annollm with 1 example per class, examples inside system message',system_content_annollm_1,model,'annollm_system','extract_last')\n",
    "    result_dataframe('annollm with 2 examples per class, examples inside system message',system_content_annollm_2,model,'annollm_system','extract_last')\n",
    "    result_dataframe('annollm with 3 examples per class, examples inside system message',system_content_annollm_3,model,'annollm_system','extract_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giving the whole document as context\n",
    "gets context length error with gpt4 but not with gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "init_system_content_context = 'You are a lawyer. Assess the risk of the following contract clause. Answer with one of these two options and nothing else: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('appending the whole contract in the system message',init_system_content_context,model,'append_contract','extract_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "     result_dataframe('appending the whole contract in the system message',init_system_content_context,model,'append_contract','extract_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4o', 'gpt-4-turbo']:\n",
    "    result_dataframe('appending the whole contract to the prompt',init_system_content_context,model,'append_contract_in_prompt','extract_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('appending the whole contract to the prompt',init_system_content_context,model,'append_contract_in_prompt','extract_first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Prompting with Embeddings\n",
    "using voyage ai's domain specific model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ic examples in the system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the embeddings for ic examples\n",
    "df_ic_examples['embedding'] = df_ic_examples['embedding'].apply(lambda x: np.array(ast.literal_eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_system_content_fewshot = f'You are a lawyer. Assess the risk of the following contract clause. \\nAnswer with one of these two options and nothing else: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.\\nHere are some examples to help you: \\n '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo-0125'\n",
    "result_dataframe('few shot with embeddings not per class, two examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=2)\n",
    "\n",
    "for model in [ 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings not per class, two examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=2)\n",
    "\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings not per class, four examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=4)\n",
    "\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings not per class, six examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings not per class, two examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=2)    \n",
    "\n",
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings not per class, four examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=4)\n",
    "\n",
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings not per class, six examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings not per class, two examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=2)\n",
    "\n",
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings not per class, four examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=4)\n",
    "\n",
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings not per class, six examples in total, in system message',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='not_per_class',n_fewshot_embed=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo-0125'\n",
    "result_dataframe('few shot with embeddings, per class, one example per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=1)\n",
    "\n",
    "for model in ['gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=1)\n",
    "\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=2)\n",
    "\n",
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=1)    \n",
    "\n",
    "for model in ['meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=2)\n",
    "\n",
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=1)\n",
    "\n",
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=2)\n",
    "\n",
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=1)\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=2)\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in system message', init_system_content_fewshot, model ,cleanining_method='extract_last',setting='few_shot_embed_system',which_ic_embed_type='per_class',n_fewshot_embed=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ic examples in the user message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_system_content_fewshot = f'You are a lawyer. Assess the risk of the following contract clause. \\nAnswer with one of these two options and nothing else: potential issue or red flag. Potential issue means there\\'s potentially a legal risk and red flag signifies high legal risk.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo-0125'\n",
    "result_dataframe('few shot with embeddings not per class, two examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings not per class, two examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings not per class, four examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings not per class, six examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings not per class, two examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings not per class, four examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings not per class, six examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings not per class, two examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings not per class, four examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings not per class, six examples in total, in prompt',init_system_content_fewshot,model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='not_per_class',n_fewshot_embed=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'gpt-3.5-turbo-0125'\n",
    "result_dataframe('few shot with embeddings, per class, one example per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4-turbo','gpt-4']:\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['meta/meta-llama-3-8b-instruct', 'meta/meta-llama-3-70b-instruct']:\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in ['claude-3-opus-20240229','claude-3-5-sonnet-20240620']:\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"unsloth_model_3_epochs:latest\" ,'unsloth_model_1_epoch:latest','unsloth_model_1_epoch_B:latest']:\n",
    "    result_dataframe('few shot with embeddings, per class, one example per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=1)\n",
    "    result_dataframe('few shot with embeddings, per class, two examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=2)\n",
    "    result_dataframe('few shot with embeddings, per class, three examples per class, in prompt', init_system_content_fewshot, model,cleanining_method='extract_last',setting='few_shot_embed_prompt',which_ic_embed_type='per_class',n_fewshot_embed=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
