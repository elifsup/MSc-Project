{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de82c8-7396-47b4-b2fb-1598c79d81f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported, UnslothTrainer, UnslothTrainingArguments, FastLanguageModel\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c461a-d65f-4ed9-843e-d537eb7747d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any. Unsloth support RoPE Scaling internally\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e659f-250c-437a-ab22-af30e76fff4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c19ee-9dff-470f-991d-5c9cfd4ee8dd",
   "metadata": {},
   "source": [
    "## creating dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666fe60a-a330-4547-bbb9-b225c394e592",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_whole = load_dataset('theatticusproject/cuad-qa', trust_remote_code=True)\n",
    "\n",
    "df_train = pd.DataFrame(dataset_whole['train'])\n",
    "df_test = pd.DataFrame(dataset_whole['test'])\n",
    "\n",
    "df_combined = pd.concat([df_train, df_test])\n",
    "\n",
    "df_cuad_combined = df_combined.drop_duplicates(subset='context')\n",
    "\n",
    "dataset_cuad =  Dataset.from_pandas(df_cuad_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cddc0f-72c5-499e-b157-ee8821eb5b42",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('nli_dataset/dev.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "documents = data['documents']\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    row = {\n",
    "        'id': doc['id'],\n",
    "        'file_name': doc['file_name'],\n",
    "        'text': doc['text'],\n",
    "        'url': doc['url']\n",
    "    }\n",
    "    rows.append(row)\n",
    "    \n",
    "df_dev = pd.DataFrame(rows)\n",
    "\n",
    "with open('nli_dataset/test.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "documents = data['documents']\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    row = {\n",
    "        'id': doc['id'],\n",
    "        'file_name': doc['file_name'],\n",
    "        'text': doc['text'],\n",
    "        'url': doc['url']\n",
    "    }\n",
    "    rows.append(row)\n",
    "    \n",
    "df_test = pd.DataFrame(rows)\n",
    "\n",
    "with open('nli_dataset/train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "documents = data['documents']\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    row = {\n",
    "        'id': doc['id'],\n",
    "        'file_name': doc['file_name'],\n",
    "        'text': doc['text'],\n",
    "        'url': doc['url']\n",
    "    }\n",
    "    rows.append(row)\n",
    "    \n",
    "df_train = pd.DataFrame(rows)\n",
    "\n",
    "df_nli_combined = pd.concat([df_dev,df_test,df_train])\n",
    "\n",
    "dataset_nli = Dataset.from_pandas(df_nli_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b3036-0772-4a68-bb2c-7a39764fdcc6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = 'source_documents'\n",
    "file_contents_list = []\n",
    "\n",
    "file_ids = []\n",
    "file_contents = []\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Open the file and read its contents into a string\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_contents.append(file.read())\n",
    "        \n",
    "        # Append the file name to the list\n",
    "        file_ids.append(filename)\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "df = pd.DataFrame({'id': file_ids, 'contract': file_contents})\n",
    "df['source'] = \"Genie\"\n",
    "df_genie = df\n",
    "\n",
    "dataset_genie = Dataset.from_pandas(df_genie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf34d7f-3684-4350-ad5c-cbf004a21cd4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract and rename columns from df_cuad_combined\n",
    "df_cuad = df_cuad_combined[['id', 'context']].rename(columns={'context': 'contract'})\n",
    "df_cuad['source'] = 'CUAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c93ed7-0547-4db4-b3f9-07d199633bf0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract and rename columns from df_nli_combined\n",
    "df_nli = df_nli_combined[['id', 'text']].rename(columns={'text': 'contract'})\n",
    "df_nli['source'] = 'NLI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a699f5-521c-4ebd-890a-2c9af889420d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the DataFrames\n",
    "df_combined = pd.concat([df_cuad, df_nli, df_genie], ignore_index=True)\n",
    "# make sure id type is consistent\n",
    "df_combined['id'] = df_combined['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54661206-05e2-4b85-9056-1b34695e79df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_combined = Dataset.from_pandas(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c289dfc-ad27-4bd2-a04a-278d25466067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa83c481-bec1-43a7-8f0f-9c5d81161b9e",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d78667-71f2-4615-9218-011df2f8e5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    #train_dataset = dataset,\n",
    "    train_dataset = dataset_combined,\n",
    "    #dataset_text_field = \"text\",\n",
    "    dataset_text_field = 'contract',\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_ratio = 0.1,\n",
    "        #max_steps = 2000,\n",
    "        #max_steps = 5,\n",
    "        num_train_epochs = 1,\n",
    "\n",
    "        # Select a 2 to 10x smaller learning rate for the embedding matrices!\n",
    "        learning_rate = 5e-6,\n",
    "        embedding_learning_rate = 1e-6,\n",
    "\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        #save_steps = 100,\n",
    "        save_steps = 50,\n",
    "        save_total_limit = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.00,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        #output_dir = \"./drive/MyDrive/Llama-3-8B-fineweb-edu-r128a32wd0lstcosinelr5e06-10BT\",\n",
    "        output_dir = 'results' # not sure?\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea030d28-2146-469e-a8d8-3f733efab994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the LoRA adapters locally\n",
    "model.save_pretrained(\"lora_model\") # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b35c6-c633-4707-b871-ea8898e32ca4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to 8bit Q8_0\n",
    "if True: model.save_pretrained_gguf(\"model_1_epoch_B\", tokenizer,)\n",
    "# add ModelFile after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b0ee73-b2e9-4786-ac60-0ea88f377129",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ollama create unsloth_model_1_epoch_B -f ./model_1_epoch_B/Modelfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078ffb2-5920-4b01-9a6f-4e8f964b9847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"hellooooo\""
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593577c-e65a-4e90-91e6-1429e88d777d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change the file path to the last checkpoint\n",
    "file_path = 'results/checkpoint-72/trainer_state.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "log_history = data['log_history']\n",
    "steps = [entry['step'] for entry in log_history]\n",
    "loss = [entry['loss'] for entry in log_history]\n",
    "\n",
    "#plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, loss, linestyle='-', color='purple')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Steps for 1 Epoch, Dataset B')\n",
    "plt.savefig('Training Loss over Steps for 1 Epoch, Dataset B', format = 'pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3087e897-aa68-4dab-8781-e5bed8653515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
