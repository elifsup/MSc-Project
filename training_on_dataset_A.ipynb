{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a398e7-f598-4e93-9e28-443a0295bc3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this \n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bb6d7-8c70-4d1e-bebe-1092741e18c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a63b7-b4bf-460e-9931-196c8a77f5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0303d43-f266-42c2-a126-9d65b5ee630e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported, UnslothTrainer, UnslothTrainingArguments, FastLanguageModel\n",
    "#from datasets import load_dataset, DatasetDict, Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd26f000-cd75-45f3-8bfe-f012ae12c0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2889cbbf-a77d-4a55-92cc-71cb1d232ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any. Unsloth support RoPE Scaling internally\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a4b3f-3383-48f5-8875-9c4dbbb3b6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa04ff-7cad-4720-ab12-159a90de0372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c00cc0-e5d3-415a-9732-8fab73351b7b",
   "metadata": {},
   "source": [
    "## cleaning further pre-training data - CUAD + ContractNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3d66c-ff1a-46de-b56c-3d4aea9d71a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_whole = load_dataset('theatticusproject/cuad-qa', trust_remote_code=True)\n",
    "\n",
    "df_train = pd.DataFrame(dataset_whole['train'])\n",
    "df_test = pd.DataFrame(dataset_whole['test'])\n",
    "\n",
    "df_combined = pd.concat([df_train, df_test])\n",
    "\n",
    "df_cuad_combined = df_combined.drop_duplicates(subset='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5fb4d3-0b90-486b-a0cd-c12dfa0698c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_cuad =  Dataset.from_pandas(df_cuad_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93abf6fd-278d-4cba-bd1e-0fb341097475",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_cuad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901a0aa8-d236-4255-a620-63e495f2591e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c650d-5689-4708-a6ea-20272ebda6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('nli_dataset/dev.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "documents = data['documents']\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    row = {\n",
    "        'id': doc['id'],\n",
    "        'file_name': doc['file_name'],\n",
    "        'text': doc['text'],\n",
    "        'url': doc['url']\n",
    "    }\n",
    "    rows.append(row)\n",
    "    \n",
    "df_dev = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b37a73-200d-4e58-91f4-b11f90fdce99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('nli_dataset/test.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "documents = data['documents']\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    row = {\n",
    "        'id': doc['id'],\n",
    "        'file_name': doc['file_name'],\n",
    "        'text': doc['text'],\n",
    "        'url': doc['url']\n",
    "    }\n",
    "    rows.append(row)\n",
    "    \n",
    "df_test = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c2808-429d-41b7-a6d1-fac80d238849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('nli_dataset/train.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "documents = data['documents']\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    row = {\n",
    "        'id': doc['id'],\n",
    "        'file_name': doc['file_name'],\n",
    "        'text': doc['text'],\n",
    "        'url': doc['url']\n",
    "    }\n",
    "    rows.append(row)\n",
    "    \n",
    "df_train = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787734b4-a23e-4677-a07b-34b69959bc9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_nli_combined = pd.concat([df_dev,df_test,df_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca3258-06ed-4f0a-80d2-fa9207baea0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_nli = Dataset.from_pandas(df_nli_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c252df-9822-49c8-b8a2-c1a1622287db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_nli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f8969-3d6d-4114-87d7-f13f654c87b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## counting number of tokens for further pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f838838-7b2d-41e8-af0f-63121f9e02eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_token_list(dataset, field):\n",
    "    \"\"\"\n",
    "    field: name of the column that contains the contracts\n",
    "    \"\"\"\n",
    "    no_of_tokens_list = []\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        contract = dataset[i][field]\n",
    "        tokens = tokenizer.encode(contract)\n",
    "        no_of_tokens = len(tokens)\n",
    "        no_of_tokens_list.append(no_of_tokens)\n",
    "    return no_of_tokens_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4980c6-05c0-4dfe-848d-f6a4b672ae78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(f\"The number of total tokens for CUAD (test + train combined) is {np.sum(create_token_list(dataset_cuad, 'context'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a74fc-99f2-48a6-bd80-b9d2683fcbf5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(f\"The number of total tokens for NLI (test + train + dev combined) is {np.sum(create_token_list(dataset_nli, 'text'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb914b48-5d50-4c6b-aee5-082e80b991f2",
   "metadata": {},
   "source": [
    "## producing the pie chart for pre-training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50169cc-bc25-4992-9917-ab6c8cb06b52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cuad = pd.read_csv('cuad_dataset.csv')\n",
    "\n",
    "def get_token_number(contract):\n",
    "    \"\"\"\n",
    "    field: name of the column that contains the contract\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(contract)\n",
    "    no_of_tokens = len(tokens)\n",
    "    return no_of_tokens\n",
    "\n",
    "df_cuad['token count'] = df_cuad['context'].apply(get_token_number)\n",
    "\n",
    "contract_type_sums = df_cuad.groupby('contract type')['token count'].sum().to_dict()\n",
    "\n",
    "contract_type_sums['non-disclosure agreement'] = 1302791\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "labels = list(contract_type_sums.keys())\n",
    "sizes = list(contract_type_sums.values())\n",
    "\n",
    "# Create a pie chart\n",
    "#colors =  plt.get_cmap('cool').colors\n",
    "\n",
    "colormap = plt.cm.tab20b\n",
    "colors = colormap(np.linspace(0, 1, len(labels)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "#plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.pie(sizes, labels=labels, colors=plt.cm.Set3.colors, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 6.5})\n",
    "#plt.legend(labels, loc=\"best\", fontsize=10)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# Add a title\n",
    "plt.title('Token Count by Contract Type')\n",
    "\n",
    "plt.savefig('pie_chart.pdf', format='pdf')\n",
    "\n",
    "# Display the pie chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4333be8e-cbf9-4927-8cc3-6d420a14b1cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## merging the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e3efb-a3a7-408d-88ba-993d3eda547f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract and rename columns from df_cuad_combined\n",
    "df_cuad = df_cuad_combined[['id', 'context']].rename(columns={'context': 'contract'})\n",
    "df_cuad['source'] = 'CUAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660606d7-0f00-46f9-af0d-b06860feb504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract and rename columns from df_nli_combined\n",
    "df_nli = df_nli_combined[['id', 'text']].rename(columns={'text': 'contract'})\n",
    "df_nli['source'] = 'NLI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae6078-eaa9-4e09-a868-033baf3b13dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the DataFrames\n",
    "df_combined = pd.concat([df_cuad, df_nli], ignore_index=True)\n",
    "# make sure id type is consistent\n",
    "df_combined['id'] = df_combined['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d87ef-f1c8-45ae-91a6-76a9fa57a570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_combined = Dataset.from_pandas(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05543798-31a6-40b5-95ca-cba359b92946",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(f\"The number of total tokens for the combined dataset (CUAD + NLI) is {np.sum(create_token_list(dataset_combined, 'contract'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31c07b-315f-40c6-be94-020762c270f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77bde67-8f87-4b0e-9a27-fda955656f6c",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9b374-56c3-49d6-9821-21ae261e925a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    #train_dataset = dataset,\n",
    "    train_dataset = dataset_combined,\n",
    "    #dataset_text_field = \"text\",\n",
    "    dataset_text_field = 'contract',\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "\n",
    "    args = UnslothTrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_ratio = 0.1,\n",
    "        #max_steps = 2000,\n",
    "        #max_steps = 5,\n",
    "        num_train_epochs = 1,\n",
    "\n",
    "        # Select a 2 to 10x smaller learning rate for the embedding matrices!\n",
    "        learning_rate = 5e-6,\n",
    "        embedding_learning_rate = 1e-6,\n",
    "\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        #save_steps = 100,\n",
    "        save_steps = 50,\n",
    "        save_total_limit = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.00,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        #output_dir = \"./drive/MyDrive/Llama-3-8B-fineweb-edu-r128a32wd0lstcosinelr5e06-10BT\",\n",
    "        output_dir = 'actual' # not sure?\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e005e-1ee5-440f-bc2f-adc7ca1a97ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the LoRA adapters locally\n",
    "model.save_pretrained(\"lora_model\") # Local saving\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a26534-20f0-4943-89a9-3fabef9436c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# installing ollama\n",
    "#!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1e043-3d72-4728-a3ac-4dbdfa97b56c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save to 8bit Q8_0\n",
    "if True: model.save_pretrained_gguf(\"model_1_epoch\", tokenizer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2bbec-51ac-4ca2-ba07-1a4b258a7a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tokenizer._ollama_modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f51fe-13d1-46f3-bd9a-c7c843bd2714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!ollama create unsloth_model_1_epoch -f ./model_1_epoch/Modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b248e-47a8-428e-9fbd-8b3136ff2e06",
   "metadata": {},
   "source": [
    "## training stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2bfe3-08e1-4b70-bf34-83c9902a2552",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change the file path to the last checkpoint\n",
    "file_path = 'actual/checkpoint-69/trainer_state.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "log_history = data['log_history']\n",
    "steps = [entry['step'] for entry in log_history]\n",
    "loss = [entry['loss'] for entry in log_history]\n",
    "\n",
    "#plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, loss, linestyle='-', color='green')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Steps for 1 Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88391aaa-c773-4594-a173-64fd279fa8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda85ab-984e-4d90-8765-c4d0675fbe30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
